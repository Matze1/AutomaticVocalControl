\chapter{Improvements}
\label{chapter:improvements}

\section{Automation}

Using the study plug-in a mixing engineer will not have to draw gain automations manually. Nevertheless it can be useful to have an automation drawn by the plug-in. On one hand side it visualises the adapted gain curve better than the gain slider contained in the UI alone. On the other hand, it can save up calculation resources when the plug-in reads its own automation instead of processing the same vocal track in a repeated way. This is not necessary in simple mixing sessions but comes in handy when the mixed musical piece contains a great number of tracks with even more digital effects on each channel. Every digital effect increases the total amount of necessary CPU power. Often single tracks are bounced in place\footnote{all effects are rendered and combined with the actual signal to a new audio file} to avoid problems in performance. When the plug-in just reads an automation it is no considerable part of this problem even if there are multiple vocal tracks using this effect.\\
For those reasons the study plug-in was extended with this feature. In principle automations are supported by the JUCE framework and it can be very simple to implement a standard automation process. The normal case would be a user interacting with the UI and the plug-in communicating these changes to the DAW on write mode. On automation read mode the changes are send back to the plug-in during playback and it does its normal processing chain with changing parameters with the user drawn timing. The study plug-in was a special case which made it more difficult to realise the automation. In case of the study plug-in the write process of the automation should not be influenced by a user at intended use. Furthermore it should just receive and multiply the adapted gain from the drawn automation at read mode.\\
Like in the Waves plug-in a button was implemented at the UI to switch between read and write mode. Therefore the plug-in always knows if it needs to adapt the gain itself. The read mode implementation was performed quite fast as it just bypasses the regular calculations and multiplies the gain value set by the DAW with the current sample. The communication between DAW and plug-in works well on this part with the predefined parameter class from JUCE. The write mode produced more problems.\\
The plug-in adapts the gain value at write mode for every sample. When this would be communicated to the DAW like in normal automation process it has to draw at least 44100 adapted gain values each second. This easily overtaxes a DAW and is more accurate as it needs to be for a acceptable result. The DAW expects just a few changes per second for the automation as its normal use case (user modifies parameter at UI) would generate. It follows that the drawn automation had to be simplified.\\
At the first attempts automation changes were only communicated when the gain adaption changes its direction (compression/amplification) or when the difference to the last drawn automation point became crucial. Unfortunately this did not work as well. The output in the DAW would have been acceptable but at some spots it made incorrect jumps. These jumps occured in duration of at most 2 samples but they were still unwanted. Due to involvement of several devices in this process the real cause of the jumps could not be figured out. Different timings and positions for the communication to the DAW and also change of the parameter values were tested. During an long early testing phase no difference or worse results were achieved before an acceptable result was found:\\
The final solution sets a automation point every 80ms as long the gain changed about at least 0.1dB.
Therefore the gain adaption is constantly drawn in the automation curve but 12,5 instead of 41000 times a second or more. It does not set a new point when the gain is not adapting as this would be redundant. There are still jumps in the curve but this is acceptable as the jumps occur rarely and gain difference is about at most 0.1dB. Additionally these jumps are now located at correct positions without smoothing, which is not essential for such small amounts of adaption.\\

\begin{figure}[H]
\includegraphics[width=\textwidth]{images/automation}
\caption{Automation written by the study plug-in into a DAW}
\end{figure}

\section{Adapting Loudness Goal}

The loudnessGoal parameter is not to understand as a gain controller. It is not designed to amplify the signal to a desired level. Instead, it should be adjusted to the actual loudness of the signal. In this way the plug-in can use its full range for changes on dynamics. For example when the loudnessGoal is set far below the signal level, the plug-in will stay at its minimal allowed gain value (initalized with -6dB) as long as it gets the high-level input. Even if it is at one end of the user defined dynamic range it will still operate in half (only negative/positive gain adaption) for most of the time. Therefore it is important to set the loudnessGoal correct. In best practice the plug-in will compress the incoming signal as much as amplifying it.\\
To simplify the selection of a fitting loudnessGoal for a user, a input meter was implemented next to the loudnessGoal slider and the current gain adaption. In this way it is easier to see if the current setting makes sense. However it still remains a problem as the perfect loudness goal possibly alters through a song. So it is difficult for a human to guess the average setting for the entire musical piece. Therefore some calculation based solutions were tested.\\
The first approach was determining a new loudnessGoal for every second. To achieve this the plug-in summed up all resulting gain values for each sample in this time period. Afterwards it calculated the average tendency (more positive or negative gain values). The offset was finally subtracted from the current loudnessGoal and the sum of the gain values got reseted.\\
Problematic with this approach was that the loudnessGoal adaption was one second to late if the signal level changed. In addition it made some advantages of the plug-in needless as it treated different parts of the vocals with different settings which results in some local benefits but leads to varying level through the whole track.\\
It follows that only analysing parts of the vocal track would not lead to a profitable result. Furthermore the plug-in should go through all critical parts of its input and therefore decide for the best suiting loudnessGoal. In conclusion a button was implemented accessible at the UI which switches the plug-in to loudnessGoal detection mode. During the time this mode is active the plug-in will not multiply the calculated gain with the signal but is still determining it, dissimilar to a regular bypass. In addition the plug-in re-adjusts its allowed gainRange for this period of time to the maximum (+/- 10dB). This is done to find a most accurate average loudness rate and it has no negativ consequences as it just endures as long as the detection mode is active. If you run the plug-in on detection mode through the full vocal track it calculates a decent loudnessGoal. To avoid the result being falsified by sections were no vocal signal is present, it only adapts on input with actual signal.\\
This is a task predestined to be done offline but due to the complexity of offline calculations in a plug-in operating in different DAWs the time was not enough to realise it in this thesis. For future work this would be a great opportunity to make use of the full ITU-R BS.1770-4 algorithm.\\
Although the loudnessGoal detection mode is probably the best current way to set the parameter, it is still allowed for a user to choose it him/herself due to own creative reasons.\\
When the loudnessGoal algorithmically adapts or is set to a new value on user terms the threshold of the plug-ins gate will change as well. Regardless of whether the average input is of small or great level the plug-in is therefore able to handle it with reasonable settings.\\

\section{Side Chain}

So far the plug-in works well on single audio tracks and reduces long term dynamics. This already lessens the work for a mixing engineer but the vocal level staying around the same amount over a whole musical piece is not necessary the wanted result. If the instrumental backtracks varies in its loudness it is desirable for the plug-in to do the same with its output gain. To do such a sing the plug-in requires additional information. Consequently a side chain input was added to its interface to realise this feature.\\
Side chains are not part of the standard I/O\footnote{I/O = input/output} layout of JUCE but supported since JUCE version 4.1. To realise another input, it was added in the BusesProperties() structure from the AudioProcessor class. As for the plug-in it is not necessary to have a side chain input, the supported bus layouts did not have to change. Therefore the embedding DAW is able to feed it with a signal but does not have to. For further testing in Logic Pro 9 the plug-in had to be revalidated for the DAW, before it accepted the new I/O layout. This was not necessary for previous algorithmic changes.\\
After implementing the new input the new information had to be used. To do this the plug-in reads the side chain buffer in its main processBlock() method. It needed information about the loudness of the backtrack (which should be fed into the side chain) to be able to determine a useful additional output gain. In process of detecting the loudness of the side chain input it is passing through the filter, RMS and gain calculations as the regular input signal does (see Fig. 5.2). This includes the transformation into logarithmic number space. Afterwards it is compared to the current loudnessGoal and the calculated difference is smoothed. Now the smoothed gain is transferred back to linear number space and it is multiplied with the gain of the parallel determination from the main input.\\
It is important for the side chain processing that it does not interfere with the main plug-in calculations. Especially the loudnessGoal must not be changed through this process. Otherwise it would corrupt its results in terms of dynamic range and make the loudnessGoal detection useless.\\
While testing in real use cases it seemed beneficial to add an additional output gain for the finally returned signal. This reduced the effort of matching vocal output level with the backtrack. It would be great if the plug-in could set the output gain itself depending on the side chain input, but as for different music styles and creative decisions there is not one right version of vocal to backtrack relation but a great number of reasonable possibilities. Nevertheless for future improvements of the plug-in this part can certainly be simplified in its user interaction.\\
The side chain feature remains an usable addition to the main plug-in but becomes no part of it as it is not automatically profitable in every use case. That is why there is button at the UI to toggle the 
side chain integration on and off. On further term this is useful as different DAWs will handle an undefined (when no input channel/bus is chosen) side chain input dissimilar. Logic Pro 9 sends for example an empty signal containing only zeros. This would effect the outcome of the plug-in when side chain integration is active as it would interpret the signal as a quiet backtrack. With the side chain activation button which is toggled off by default, there is no urgent need of a silence detection always running in the plug-ins side chain processing chain.\\
A remaining question for the side chain implementation were how to set the average time coefficients for RMS calculations and gain adaption (see 5.6). On one hand it should not react on small changes for example when a musician in the instrumental is just accentuating certain beats, on the other hand it needs to react fast enough to calculate an appropriate gain for the first sung words of a new song part with a different loudness level. Not negligible that it operates with the lookahead already realised for the plug-ins main use.\\
Additionally in the first approach it turned out to be a difficult problem for the side chain gain adaption to deal with instrumental breaks of longer duration (up to a full bar). While most of the instruments are pausing during those breaks the vocals should stay at the same level as it is often used to emphasize the remaining musicians. With the current implementation of side chain adaption instrumental breaks were causing a parallel slowly falling vocal level. Later with the implementation of the idle time (see 5.4) at gain adaption this behaviour could be avoided for the most part.\\

\begin{figure}[H]
\includegraphics[width=\textwidth]{images/chain02}
\caption{Improved processing chain}
\end{figure}

\section{Idle Time}

During the comparison of the study plug-in and the “Vocal Rider” it emerged the idea of implementing a idle time before fading to 0dB gain for the study plug-in. The effect of such a idle time is that the plug-in will ignore short gaps between vocal signals. Therefore the plug-in does not change the adapted gain for example when a singer does a short rhythmic break in his/her vocals. So it will just use the actual vocals in the input for gain adaption similar to how a mixing engineer would do it. Due to a reasonable short duration of the idle time it is still able to adapt to 0dB gain for parts without singing. Following there will be no problematic danger of amplifying unwanted noise. The short period after a vocal signal and before a part of silence were the plug-in is still idle will not remain much longer than the vocal decay and is even shortened by the amount of lookahead delay.\\
At the first approach in implementing this feature the function of the gate was expanded. Every time the input was below the threshold, the current sample was replaced by the last one above for as long as the idle time was set. Due to the last sample above the threshold still being at proportional low level it did not work as planned. The subsequently gain adapting was consequently falling on even lower results than without the change at the gate because at idle time it got values near the lowest possible one which was just not set to the loudnessGoal by the gate. Maybe it could be fixed by replacing the samples at idle time with a RMS value from a sample further ahead, but this would require a additional memory for past samples and it seemed to complicated.\\
The current implementation is therefore based on the plan that the plug-in should detect at the gate if there are no vocals and then freeze the current gain at the following gain adaption. As the gain adaption is much slower due to compress/amplification time smoothing than the RMS averaging before the gate, it freezes the gain before it is able to adapt to the level change. For reasons of simplification everything was implemented in the updateGain method.\\

\begin{lstlisting}[frame=single]
double AutoVocalCtrlAudioProcessor::updateGain(double sample, 
double lastGn)
{
    if (sample != *loudnessGoal) {
        idleCount = 0;
    } else if (idleCount < maxIdleSamples) {
        idleCount++;
        return lastGn;
    }
...
}
\end{lstlisting}

It detects if the current level is below gate threshold by comparing the sample with the loudnessGoal. If the transferred RMS averaged sample is at the exact value of the loudnessGoal it can be assumed that the gate replaced its actual value. The rare case of a sample being randomly at exact the level of the loudnessGoal and therefore stop the gain adaption cant be eliminated in this simple implementation. Nevertheless this makes no a noticeable difference as it just stops the slow gain adaption for one single sample (max 1/44100 sec in expected use case). At the first sample differing from the loudnessGoal the idle timer is reset and the gain adaption continuous. When the maximum idle time is reached it has the same effect apart from resetting the idle time counter.\\
With the idle time working well in the main processing chain of the plug-in it was the next step to think about its advantages in terms of side chain integration. At this time there was still a problem with instrumental breaks and their unwanted impact on the calculated gain correction. Therefore a implementation of idle time similar to the already existing one for the main input was used. At the final side chain calculations it was implemented and adjusted the length of the maximum idle time with tests in a real mixing environment. The result with a reasonable set maximum was quite good as it severely reduced the gain drop during instrumental breaks as long as the side chain input level was adapted to the loudnessGoal. Consequently the UI was expanded with a pre gain slider for the side chain input which adds up before the comparison to the loudnessGoal. Controlling the input level of the side chain signal was possible before via a level controlled bus send but now the mixing engineer is able to do it all at one place while check the level meters for both signals right next to each other at the UI. As it was still difficult to adjust it correct for a whole song a self setting algorithm for the input gain was added to the already existing detection mode. As said before this would be significant better to do in an offline thread but works in real time for now.\\

\begin{figure}[H]
\includegraphics[width=0.8\textwidth]{images/automation2LookIdle}
	\centering
	\caption{Idle time and lookahead marked at automation written by the study plug-in}
\end{figure}

\section{Wet/Dry}

Many plug-in effects for DAWs have an additional slider to adjust the wet/dry ratio of their outcome. In these terms 100% “dry” is similar to the signal without the effect and 100% “wet” is a fully processed effect on the signal. This reduces the effort which would be necessary for sending the signal on a second track with the effect inserted to mix both tracks together in wanted proportions.\\
In consideration of the use of such a slider in the plug-in of this thesis, it seemed useful at first as it ables a user to set the intensity of dynamic compression. On the other hand this is already possible in a slightly different way with better outcome, by changing the current gainRange. In addition that this is feature has its main use in creative work, which is not the main objective of this plug-in, the final plug-in will not include a wet/dry slider for now. This decision was made with the intension of simplifying the UI to its foundation followed by the reduction of the settable parameters.\\

\section{Parameter Reduction}

As the plug-in slowly reaches its final state, it was necessary to transfer some settable parameters to fixed constants. In development it was useful to be able to change the important parameters while in runtime for example the compress and amplification times. Now it already emphasised which settings will  result in the best outcome. Small changes could be slightly better depending on the current circumstances but they are not required for a good result. Additionally with wrong application these parameters could create a poor result. Therefore and with the likely possibilities of a user not knowing what each of these parameters does, it seemed to be advantageous to hide those as constants, invisible at the UI.\\
This parameter reduction was applied to the lookahead delay, compress time, amplification time, RMS time, idle time, the side chain time constants and like already described, the gate. With the experience from testing the plug-in with many different settings in various circumstances the default choices for the parameters already got to reasonable values.\\
With a bad lookahead delay the gain adaption could happen to early or it has no noticeable effect. In the process of testing it commuted in at 60ms of delay as a good default value. For the parameter reduction it got set to 50ms as this resulted in the best outcome at additional test with special precision on the lookahead delay. A further test with a comparison of the drawn automation and the vocal signal waveform validated the new setting (see Fig. 5.1, 5.3).\\
The RMS averaging time shouldn’t be to long as this adds up on the total reaction time of the plug-in. On the other hand it needs a big enough time window to calculate a useful average. At the beginning of development it was set to 60ms. The comparison to the Waves “Vocal Rider” resulted in very small time windows (down to 8ms) for the averaging at this plug-in, to imitate the outcome. As this seemed a bit fast in consideration of previous experiences, it got into further tests with altering RMS time in collaboration with changing compress and amplification times. As result the RMS time is finally set to 30ms.\\
With the initialisation of two different attack times for compression and expansion it was manifested that the expansion time would be greater then the compression time. Still the final settings were not yet set. So again, the comparison to the “Vocal Rider” served as an inspiration. Though with a expansion time above two seconds it was not reacting fast enough to achieve the planned results, especially compared to the compression. As consequence the expansion time came down to 1500ms for the final build.\\
The compression time results from the comparison with the “Vocal Rider” were similar to a slow compressor and therefore still to fast to fit the idea of this thesis. As follows it had to be tested independently. This lastly resulted in a compression time of 600ms working out and, even though it was not planned, a slope of 1/3 at gain reduction. The reason for a additional slope were some vocal parts which got their level to low after compression. With a slope only at compression the gain adaption is balanced.\\
The idle time is set after considerations on the small gaps between phrases on vocal tracks. As it should be long enough to endure most of these gaps it is finally set to 500ms. A longer duration for the main functionality of the plug-in seemed unreasonable as it mainly extends the part after a vocal signal where the plug-in would just amplify noise.\\
For the side chain input the plug-in takes a idle time set to two seconds to be able to ignore instrumental breaks. With a shorter setting it still results in decreasing vocal level while those breaks are happening. Furthermore it uses the same RMS time like the main input and smoothes the resulting gain similar slow to the amplification time with a time coefficient adjusted to 1600ms.\\
The gate just adapts with the loudnessGoal like described in 5.2 and is not settable in the UI anymore.\\

\section{last CAP OF PLUG-IN}

\section{Design}

