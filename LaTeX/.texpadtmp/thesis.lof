\select@language {english}
\select@language {english}
\select@language {english}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces A basic voice conversion framework used by most VC approaches. The source speaker signal is split into three components using a parametric vocoder analysis. Then, these three components are converted separately. The fundamental frequency and the spectral envelope are converted, while the aperiodicity information is usually kept unchanged. The dashed line depicts copying.\relax }}{5}{figure.caption.7}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The fundamental frequency F0 in the time domain can be seen as a (nearly) perfect sine wave. Speech consists of F0 plus its harmonics at different phases and amplitudes. Then, the signal is still periodic but does not look like a sine wave.\relax }}{9}{figure.caption.8}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Shown are two F0 candidates given an artificially created signal. In red are the distances that are measured for every signal and time step.\relax }}{10}{figure.caption.9}
\contentsline {figure}{\numberline {2.3}{\ignorespaces An artificially created example of the cepstral representation of the log power spectrum $p_s(\tau )$ (black), the si function $l_s(\tau )$ that cuts out the fundamental frequency peaks at multiples of $T_0$ (red), and the cosine boosting function $l_q(\tau )$ (blue).\relax }}{12}{figure.caption.10}
\contentsline {figure}{\numberline {2.4}{\ignorespaces A comparison of the two possible functions to what respect G can be optimized. $\qopname \relax o{log}(1 - D(G(z)))$ diverges for $D(G(z)) \rightarrow 1$ while $\qopname \relax o{log}(D(G(z)))$ diverges for $D(G(z)) \rightarrow 0$. However, as $D(G(z))$ will never have the values $0$ or $1$ because of the sigmoid activation function at D's output, this is not a problem.\relax }}{19}{figure.caption.11}
\contentsline {figure}{\numberline {2.5}{\ignorespaces An example of how a warping function in VTLN might look like and how it affects the spectral envelope of a speech sound.\relax }}{23}{figure.caption.12}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Histograms of the fundamental frequencies for a male speaker excluding zero, which means silence and/or unvoiced speech. In (\subref {subfig:log-f0}), log-F0 is shown, which looks more similar to a Gaussian distribution than the more skewed left (\subref {subfig:f0}) showing F0 directly.\relax }}{25}{figure.caption.13}
\contentsline {figure}{\numberline {3.2}{\ignorespaces An example for how the warping function looks like, given the source and target speaker's mean spectral envelopes.\relax }}{28}{figure.caption.14}
\contentsline {figure}{\numberline {3.3}{\ignorespaces A so-called formant map. Given are the mean frequencies of the first and second formants of a sound and their corresponding phonetic sound description across many speakers. Different speakers have similar but deviating mean formants for the same sounds. Here, only vowels in International Phonetic Alphabet (IPA) notation are depicted. The data for this visualization was taken from \cite {catford2001practical}.\relax }}{29}{figure.caption.15}
\contentsline {figure}{\numberline {3.4}{\ignorespaces A depiction of our proposed architecture. A Gaussian Mixture Model (GMM) applies a soft-clustering on the second to 21\textsuperscript {st} cepstral coefficients of the source speaker's spectral envelope and categorizes it into hopefully useful clusters that represent the speaker independent linguistic information of the sound. Three concatenated feature vectors are then fed through a neural network, the generator G, that reconstructs the target's cepstral features from the GMM features. The neural network is supported by another neural network, the discriminator D, that is supposed to make the reconstructed sound more natural.\relax }}{31}{figure.caption.16}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Comparison of two generated examples for the same input by the given architecture with and without the additional use of the discriminator network. In (\subref {subfig:without_gan}) no additional GAN loss was used. The spectrogram looks like a blurred version of (\subref {subfig:with_gan}), which has more detail structure. This can be seen especially at 0.3 seconds, 0.5 seconds, and 0.7 seconds.\relax }}{34}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Two screenshots showing the subjective evaluation test we conducted. The language of the test was German as this was the native language of all subjects.\relax }}{42}{figure.caption.18}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Boxplots describing the naturalness scores provided by their respective test subjects. Both plots are based on the same set of source-target speaker pairs.\relax }}{48}{figure.caption.20}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Distributions of the naturalness ratings for every system tested.\relax }}{49}{figure.caption.21}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Boxplots describing the naturalness scores given the source-target gender combination.\relax }}{51}{figure.caption.22}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Barcharts describing the voted similarity to the source speaker as a reference with respect to the given confidence choices.\relax }}{52}{figure.caption.23}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Barcharts describing the voted similarity to the target speaker as a reference with respect to the given confidence choices.\relax }}{53}{figure.caption.24}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Naturalness and similarity scores plotted simultaneously.\relax }}{55}{figure.caption.26}
\addvspace {10\p@ }
\addvspace {10\p@ }
